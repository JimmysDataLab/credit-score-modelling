{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d72186d0-b465-409a-9bf6-4b1ab6f17025",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, LongType\n",
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, VectorIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6d3aae9-4f1a-4c4b-ba90-c0b8d68a71fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 9\n",
    "spark_master = os.environ.get(\"SPARK_MASTER_URL\")\n",
    "train_path = os.path.join(os.environ.get(\"TRAIN_PATH\"),str(SEED))\n",
    "test_path = os.path.join(os.environ.get(\"TEST_PATH\"),str(SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "732f0cef-39b3-42c9-a9f3-a1da7cd9336a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize spark session\n",
    "spark_master = os.environ.get(\"SPARK_MASTER_URL\")\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Random-Forest-Classifier\") \\\n",
    "    .master(spark_master) \\\n",
    "    .getOrCreate()\n",
    "\n",
    "logger = logging.getLogger(\"py4j\")\n",
    "logger.setLevel(logging.ERROR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7534b841-babe-4b09-9d4e-ab766655f09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"X1\", LongType(), True),\n",
    "    StructField(\"X2\", LongType(), True),\n",
    "    StructField(\"X3\", LongType(), True),\n",
    "    StructField(\"X4\", LongType(), True),\n",
    "    StructField(\"X5\", LongType(), True),\n",
    "    StructField(\"X6\", LongType(), True),\n",
    "    StructField(\"X7\", LongType(), True),\n",
    "    StructField(\"X8\", LongType(), True),\n",
    "    StructField(\"X9\", LongType(), True),\n",
    "    StructField(\"X10\", LongType(), True),\n",
    "    StructField(\"X11\", LongType(), True),\n",
    "    StructField(\"X12\", LongType(), True),\n",
    "    StructField(\"X13\", LongType(), True),\n",
    "    StructField(\"X14\", LongType(), True),\n",
    "    StructField(\"X15\", LongType(), True),\n",
    "    StructField(\"X16\", LongType(), True),\n",
    "    StructField(\"X17\", LongType(), True),\n",
    "    StructField(\"X18\", LongType(), True),\n",
    "    StructField(\"X19\", LongType(), True),\n",
    "    StructField(\"X20\", LongType(), True),\n",
    "    StructField(\"X21\", LongType(), True),\n",
    "    StructField(\"X22\", LongType(), True),\n",
    "    StructField(\"X23\", LongType(), True),\n",
    "    StructField(\"Y\", LongType(), True)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20bdc04f-e676-4906-99ba-37284556e3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the DataFrame from the saved Parquet file\n",
    "if os.path.exists(train_path) and os.path.exists(test_path):\n",
    "    train = spark.read.schema(schema).parquet(train_path)\n",
    "    test = spark.read.schema(schema).parquet(test_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21b032e-648a-451f-8886-ab5e2345afe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of numerical and categorical columns\n",
    "target = ['Y']\n",
    "num_feat = ['X1','X5','X12','X13','X14','X15','X16','X17','X18','X19','X20','X21','X22','X23']\n",
    "cat_feat = [col for col in train.columns if col not in num_feat+target]\n",
    "cat_feat_indexed = [f\"{col}_i\" for col in cat_feat]\n",
    "cat_feat_encoded = [f\"{col}_e\" for col in cat_feat_indexed]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b724ac74-0c96-4b76-b68c-d196a89bbab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Transformations\n",
    "string_indexer = StringIndexer(inputCols=cat_feat, outputCols=cat_feat_indexed, handleInvalid='keep')\n",
    "hot_encoder = OneHotEncoder(inputCols=cat_feat_indexed, outputCols=cat_feat_encoded, handleInvalid='keep')\n",
    "vector_assembler_1 = VectorAssembler(inputCols=num_feat+cat_feat_encoded,outputCol=\"features\")\n",
    "\n",
    "# Target Transformations\n",
    "string_indexer_target = StringIndexer(inputCol='Y',outputCol='Y_i',handleInvalid='keep')\n",
    "hot_encoder_target = OneHotEncoder(inputCol='Y_i', outputCol='Y_i_e',handleInvalid='keep')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5403c21c-a5eb-400d-8644-c6c18cd3bba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector Indexing (might be better for trees)\n",
    "vector_assembler_2 = VectorAssembler(inputCols=num_feat+cat_feat,\\\n",
    "                                     outputCol=\"features\")\n",
    "vector_indexer = VectorIndexer(maxCategories=15,inputCol=\"features\",\\\n",
    "                               outputCol=\"indexed_features\")\n",
    "\n",
    "# Target\n",
    "vector_indexer_target = VectorIndexer(maxCategories=15,inputCol='Y',\\\n",
    "                               outputCol=\"indexed_target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ad25b8-af69-4c3d-83f9-05809e1557cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline\n",
    "pipeline1 = Pipeline(stages=[string_indexer, \\\n",
    "                            hot_encoder, \\\n",
    "                            vector_assembler_1, \\\n",
    "                            string_indexer_target, \\\n",
    "                            hot_encoder_target])\n",
    "train_1 = pipeline1.fit(train).transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb35bf85-8e20-4308-b440-b6247d581936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline\n",
    "pipeline2 = Pipeline(stages=[vector_assembler_2,\\\n",
    "                            vector_indexer,\\\n",
    "                            vector_indexer_target])\n",
    "train_2 = pipeline2.fit(train).transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "638f7b02-d7c1-4aff-b163-ce3cee6b6903",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
